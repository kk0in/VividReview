{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724079794.268603 42502741 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../annotations/11/1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../annotations/11/1.png\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[0;32m---> 64\u001b[0m \u001b[43mdetect_handwritten_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 13\u001b[0m, in \u001b[0;36mdetect_handwritten_text\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m client \u001b[38;5;241m=\u001b[39m vision\u001b[38;5;241m.\u001b[39mImageAnnotatorClient()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 이미지 파일을 읽고 Vision API에 전송\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image_file:\n\u001b[1;32m     14\u001b[0m     content \u001b[38;5;241m=\u001b[39m image_file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     16\u001b[0m image \u001b[38;5;241m=\u001b[39m vision\u001b[38;5;241m.\u001b[39mImage(content\u001b[38;5;241m=\u001b[39mcontent)\n",
      "File \u001b[0;32m~/Desktop/git/VividReview/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../annotations/11/1.png'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "\n",
    "def detect_handwritten_text(image_path):\n",
    "    # 환경 변수로 Google Cloud 서비스 계정 키 경로 설정\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../disco-beach-433010-q6-bf0ff037eb46.json'\n",
    "\n",
    "    # Google Cloud Vision 클라이언트 설정\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # 이미지 파일을 읽고 Vision API에 전송\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "    image_context = vision.ImageContext(language_hints=[\"en-t-i0-handwrit\"])\n",
    "\n",
    "    # 손글씨 인식 수행\n",
    "    response = client.document_text_detection(image=image, image_context=image_context)\n",
    "\n",
    "    # print(response)\n",
    "\n",
    "    # for page in response.full_text_annotation.pages:\n",
    "    #     for block in page.blocks:\n",
    "    #         print(f\"\\nBlock confidence: {block.confidence}\\n\")\n",
    "\n",
    "    #         for paragraph in block.paragraphs:\n",
    "    #             print(\"Paragraph confidence: {}\".format(paragraph.confidence))\n",
    "\n",
    "    #             for word in paragraph.words:\n",
    "    #                 word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "    #                 print(\n",
    "    #                     \"Word text: {} (confidence: {})\".format(\n",
    "    #                         word_text, word.confidence\n",
    "    #                     )\n",
    "    #                 )\n",
    "\n",
    "    #                 for symbol in word.symbols:\n",
    "    #                     print(\n",
    "    #                         \"\\tSymbol: {} (confidence: {})\".format(\n",
    "    #                             symbol.text, symbol.confidence\n",
    "    #                         )\n",
    "    #                     )\n",
    "\n",
    "    # if response.error.message:\n",
    "    #     raise Exception(\n",
    "    #         \"{}\\nFor more info on error messages, check: \"\n",
    "    #         \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "    #     )\n",
    "\n",
    "    # 결과 출력\n",
    "    if response.text_annotations:\n",
    "        print(response.text_annotations[0].description)\n",
    "    else:\n",
    "        print('No text detected.')\n",
    "    \n",
    "    # 오류 처리    \n",
    "    if response.error.message:\n",
    "        raise Exception(f'{response.error.message}')\n",
    "\n",
    "image_path = \"../annotations/11/1.png\"  \n",
    "\n",
    "detect_handwritten_text(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def remove_transparency(image_path):\n",
    "    # PNG 이미지를 불러오기 (투명 배경 포함)\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # 알파 채널이 있는지 확인\n",
    "    if image.shape[2] == 4:\n",
    "        # 알파 채널 분리\n",
    "        b, g, r, a = cv2.split(image)\n",
    "        \n",
    "        # 투명한 영역을 흰색 배경으로 채우기\n",
    "        alpha_inv = cv2.bitwise_not(a)\n",
    "        white_background = np.full_like(a, 255)\n",
    "        b = cv2.bitwise_or(b, white_background, mask=alpha_inv)\n",
    "        g = cv2.bitwise_or(g, white_background, mask=alpha_inv)\n",
    "        r = cv2.bitwise_or(r, white_background, mask=alpha_inv)\n",
    "\n",
    "        # 다시 합쳐서 BGR 이미지로 변환\n",
    "        image = cv2.merge([b, g, r])\n",
    "\n",
    "    # 저장된 이미지 반환\n",
    "    cv2.imwrite(image_path, image)\n",
    "    \n",
    "\n",
    "image_path = \"../annotations/11/drawing_2.png\"  \n",
    "remove_transparency(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "dic = {\"1\":1, \"2\":2}\n",
    "\n",
    "print(len(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
