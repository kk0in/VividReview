{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../lasso/10/7/1/temp.png\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized script text: {\"caption\": \"Semantic Gap\", \"result\": \"In Lecture 2 of CS231N, the instructor introduces the concept of the 'semantic gap' in the context of image classification. This gap represents the challenge of converting thousands of pixel values seen by the computer into meaningful semantic labels like 'cat' or 'dog'. The image shows the words 'Semantic Gap', referring to this disparity between raw pixel data and human-like understanding of images. The lecture emphasizes the difficulty for algorithms to effectively bridge this gap due to variations in lighting, viewpoint, deformation, occlusion, background clutter, and intra-class variation.\"}\n",
      "Summary saved to ../lasso/10/7/1/summarize/ver_1.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import base64\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "PDF = './pdfs'\n",
    "TOC = './tocs'\n",
    "IMAGE = '../images'\n",
    "SCRIPT = '../scripts'\n",
    "SPM = '../spms'\n",
    "LASSO = '../lasso'\n",
    "# OpenAI API Key\n",
    "api_key = \"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\"\n",
    "\n",
    "# Path to your image and script\n",
    "project_id = 10\n",
    "page_number = 7\n",
    "lasso_id = 1\n",
    "script_path = os.path.join(SCRIPT, f\"test_transcription.json\")\n",
    "lasso_path = os.path.join(LASSO, f\"{project_id}\", f\"{page_number}\", f\"{lasso_id}\")\n",
    "os.makedirs(lasso_path, exist_ok=True)\n",
    "image_list = [file for file in os.listdir(lasso_path) if file.endswith('.png')]\n",
    "lasso_image = os.path.join(lasso_path, image_list[0])\n",
    "\n",
    "\n",
    "def sanitize_filename(input_string):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"\", input_string).strip().replace(\" \", \"_\")\n",
    "   \n",
    "\n",
    "def replace_space_with_underscore(input_string):\n",
    "    return input_string.strip().replace(\" \", \"_\")\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Read script file\n",
    "def read_script(script_path):\n",
    "    with open(script_path, \"r\") as script_file:\n",
    "        script_content = script_file.read()\n",
    "        return json.loads(script_content)\n",
    "\n",
    "encoded_image = [{\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{encode_image(lasso_image)}\"}}] \n",
    "\n",
    "# Read the script\n",
    "prompt_option = [\"summarize\", \"translate to korean\"]\n",
    "prompt = prompt_option[0]\n",
    "script_content = read_script(script_path)\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "# Creating the content for the messages\n",
    "content = [\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": (\n",
    "            \"Given the following image, which is a captured portion of a lecture notes page, and the lecture script, \"\n",
    "            f\"please {prompt} in context based on the script, \"\n",
    "            \"and please caption the image with a description that is no longer than three words. \"\n",
    "            \"The output should be in the format: {\\\"caption\\\": \\\"string\\\", \\\"result\\\": \\\"string\\\"}. \"\n",
    "            f\"Lecture script: {script_content} \"\n",
    "        )\n",
    "    },\n",
    "] + encoded_image\n",
    "\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"response_format\": {\"type\": \"json_object\"},\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant designed to output JSON.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 2000,\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "# Get the response\n",
    "response_data = response.json()\n",
    "\n",
    "if 'choices' in response_data and len(response_data['choices']) > 0:\n",
    "    # 요약된 스크립트 내용 파싱\n",
    "    result_text = response_data['choices'][0]['message']['content']\n",
    "    print(\"Summarized script text:\", result_text)\n",
    "    \n",
    "    try:\n",
    "        result_data = json.loads(result_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        result_data = {\"error\": \"Failed to decode JSON\"}\n",
    "else:\n",
    "    print(\"Error: 'choices' key not found in the response\")\n",
    "    result_data = {\"error\": \"Failed to retrieve summary\"}\n",
    "\n",
    "# 이미지 파일 이름 변경\n",
    "if os.path.basename(lasso_image).startswith(\"temp\"):    \n",
    "    caption = result_data.get('caption', f'{lasso_id}')\n",
    "    sanitized_caption = sanitize_filename(caption)\n",
    "    new_image_name = f\"{sanitized_caption}.png\"\n",
    "    new_image_path = os.path.join(lasso_path, new_image_name)        \n",
    "    os.rename(lasso_image, new_image_path)\n",
    "\n",
    "# 요약된 내용 JSON 파일로 저장\n",
    "result_path = os.path.join(lasso_path, sanitize_filename(prompt))\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "result_json_path = os.path.join(result_path, f\"ver_1.json\")\n",
    "with open(result_json_path, \"w\") as json_file:\n",
    "    json.dump(result_data, json_file, indent=4)\n",
    "\n",
    "print(f\"Summary saved to {result_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate_to_korean\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_str = prompt_option[1]\n",
    "output_str = replace_space_with_underscore(input_str)\n",
    "print(output_str)  # 결과: This_is_a_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../lasso/10/7/1/summarize\n"
     ]
    }
   ],
   "source": [
    "result_path = os.path.join(LASSO, str(project_id), str(page_number), str(lasso_id), sanitize_filename(prompt))\n",
    "print(result_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../lasso/10/8\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def issue_lasso_id(project_id: int, page_num: int) -> int:\n",
    "    \"\"\"\n",
    "    지정된 프로젝트와 페이지에 대해 새로운 lasso_id를 발급하는 함수.\n",
    "    \n",
    "    :param project_id: 프로젝트의 ID\n",
    "    :param page_num: 페이지 번호\n",
    "    :return: 새로운 lasso_id\n",
    "    \"\"\"\n",
    "    lasso_path = os.path.join(LASSO, str(project_id), str(page_num))\n",
    "    print(lasso_path)\n",
    "    if not os.path.exists(lasso_path):\n",
    "        os.makedirs(lasso_path, exist_ok=True)\n",
    "        return 1\n",
    "    \n",
    "    existing_lasso_ids = [\n",
    "        int(f.split('.')[0]) for f in os.listdir(lasso_path)\n",
    "        if f.split('.')[0].isdigit()\n",
    "    ]\n",
    "    \n",
    "    if existing_lasso_ids:\n",
    "        return max(existing_lasso_ids) + 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "project_id = 10\n",
    "page_num = 8\n",
    "print(issue_lasso_id(project_id, page_number))  # 결과: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarize\n"
     ]
    }
   ],
   "source": [
    "prompt_option = [\"summarize\", \"translate to korean\"]\n",
    "prompt = prompt_option[0]\n",
    "\n",
    "print(prompt)  # 결과: summarize    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed result: - In Lecture 2 of CS231N, the instructor introduces the concept of the 'semantic gap' in the context of image classification.\n",
      "- This gap represents the challenge of converting thousands of pixel values seen by the computer into meaningful semantic labels like 'cat' or 'dog'.\n",
      "- The image shows the words 'Semantic Gap', referring to this disparity between raw pixel data and human-like understanding of images.\n",
      "- The lecture emphasizes the difficulty for algorithms to effectively bridge this gap due to:\n",
      "  - Variations in lighting\n",
      "  - Viewpoint\n",
      "  - Deformation\n",
      "  - Occlusion\n",
      "  - Background clutter\n",
      "  - Intra-class variation\n"
     ]
    }
   ],
   "source": [
    "transform_type = \"bullet_point\"\n",
    "version = 1\n",
    "page_num = 7\n",
    "result_path = os.path.join(LASSO, str(project_id), str(page_num), str(lasso_id), sanitize_filename(prompt))\n",
    "result_json_path = os.path.join(result_path, f\"{version}.json\")\n",
    "    \n",
    "with open(result_json_path, \"r\") as json_file:\n",
    "    lasso_answer = json.load(json_file)\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "# 변환 타입에 따른 프롬프트 생성\n",
    "if transform_type == \"regenerate\":\n",
    "    content = (\n",
    "        \"Please regenerate the following answer in a different way while keeping the meaning the same. \"\n",
    "        f\"Answer: {lasso_answer['result']}\"\n",
    "    )\n",
    "elif transform_type == \"shorten\":\n",
    "    content = (\n",
    "        \"Please shorten the following answer while retaining the key points. \"\n",
    "        f\"Answer: {lasso_answer['result']}\"\n",
    "    )\n",
    "elif transform_type == \"bullet_point\":\n",
    "    content = (\n",
    "        \"Please convert the following answer into a list of bullet points. \"\n",
    "        f\"Answer: {lasso_answer['result']}\"\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown transform_type: {transform_type}\")\n",
    "\n",
    "# OpenAI GPT-4 API 요청 준비\n",
    "payload = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 2000,\n",
    "}\n",
    "\n",
    "# GPT-4 API 호출\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "response_data = response.json()\n",
    "\n",
    "# 응답에서 변환된 결과 추출\n",
    "if 'choices' in response_data and len(response_data['choices']) > 0:\n",
    "    transformed_result = response_data['choices'][0]['message']['content']\n",
    "    print(\"Transformed result:\", transformed_result)\n",
    "\n",
    "    transformed_data =  {\n",
    "        \"caption\": lasso_answer.get(\"caption\", \"untitled\"),\n",
    "        \"result\": transformed_result\n",
    "    }\n",
    "else:\n",
    "    print(\"Error: 'choices' key not found in the response\")\n",
    "    transformed_data = {\"error\": \"Failed to transform the answer\"}\n",
    "\n",
    "\n",
    "version_count = len([f for f in os.listdir(result_path) if f.endswith('.json')]) + 1\n",
    "transform_json_path = os.path.join(result_path, f\"{version_count}.json\")\n",
    "with open(transform_json_path, \"w\") as json_file:\n",
    "    json.dump(transformed_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
